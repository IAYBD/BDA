{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre alumno: Rafael Navarro Gómez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Práctica HDFS: Comandos del sistema de archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En este ejercicio vamos a revisar algunos de los comandos que ofrece la shell del sistema de archivos de Hadoop para interactuar con  HDFS.\n",
    "\n",
    "Muchos de los comandos funcionan de modo similiar a como lo hace su comando homólogo en Unix.\n",
    "\n",
    "Para interactuar con HDFS se escribe en la linea de comandos de nuestro sistema:\n",
    "\n",
    "hdfs dfs -arg\n",
    "\n",
    "Donde arg puede ser alguno de los comandos que veremos a continuación.\n",
    "\n",
    "La lista completa puede consultarse en:\n",
    "https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mkdir\n",
    "\n",
    "Crea un directorio en la ruta que especifiquemos. Normalmente se crea un directorio dentro del directorio raiz que será el que utilice cada usuario. Si el directorio se crea correctamente no muestra información al respecto, en caso contrario mostrará un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ls\n",
    "Se utiliza para mostrar el contenido de un determinado directorio. Con la opción -R el listado que muestra es recursivo.\n",
    "Hay que realizar la consulta partiendo del directorio raíz / , en caso contrario mostrará:\n",
    "ls: `.': No such file or directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:41 /ej_hdfs\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:41 /user\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### touchz\n",
    "\n",
    "Crea un archivo vacío en el directorio que se indique. En el caso de que el archivo ya exista no lo sobrescribe.\n",
    "Tambien existe el comando touch, que sí que lo hace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -touchz /ej_hdfs/file1.txt\n",
    "! hdfs dfs -ls /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copyToLocal (o) get\n",
    "\n",
    "Copia archivos desde HDFS a nuestro sistema local. Hay que especificar tanto la ruta de HDFS como la ruta de nuestro directorio local donde queremos copiar el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "-rw-r--r-- 1 root root 11583 Oct 14 17:41 UD1-Actividad_Comandos_HDFS.ipynb\n",
      "-rw-r--r-- 1 root root     0 Oct 14 17:42 file1.txt\n",
      "drwxr-xr-x 1 1000 1000  4096 Oct 14 17:40 hadoop\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -get /ej_hdfs/file1.txt ./\n",
    "! ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copyFromLocal (o) put\n",
    "\n",
    "Copia archivos desde nuestro sistema local a HDFS. Hay que espcificar tanto la ruta de nuestro directorio local como la ruta donde queremos copiar el archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/file2.txt\n"
     ]
    }
   ],
   "source": [
    "! echo \"File 2\" > file2.txt\n",
    "! hdfs dfs -put ./file2.txt /ej_hdfs/file2.txt\n",
    "! hdfs dfs -ls /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cp\n",
    "\n",
    "Copia ficheros dentro de HDFS. Hay que especificar la rutas origen y destino del fichero a copiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/file2.txt\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:42 /ej_hdfs/file4.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cp /ej_hdfs/file1.txt /ej_hdfs/file4.txt\n",
    "! hdfs dfs -ls /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mv\n",
    "\n",
    "Mueve ficheros entre directorios de HDFS, tambien se utiliza para renombrar ficheros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! hdfs dfs -mv /ej_hdfs/file4.txt /ej_hdfs/file3.txt\n",
    "! hdfs dfs -ls /ej_hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/file2.txt\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:42 /ej_hdfs/file3.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mv /ej_hdfs/file4.txt /ej_hdfs/file3.txt\n",
    "! hdfs dfs -ls /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rm\n",
    "\n",
    "Borra archivos y directorios vacíos de HDFS. Con la opción -R hace el borrado de modo recursivo en directorios, útil cuando estos nos están vacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /ej_hdfs/file3.txt\n",
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/file2.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm /ej_hdfs/file3.txt\n",
    "! hdfs dfs -ls /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### du\n",
    "\n",
    "Muestra el tamaño de cada archivo en un directorio. Con la opción -v muestra una línea de cabecera con el nombre de las columnas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE  DISK_SPACE_CONSUMED_WITH_ALL_REPLICAS  FULL_PATH_NAME\n",
      "0     0                                      /ej_hdfs/file1.txt\n",
      "7     7                                      /ej_hdfs/file2.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -du -v /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df\n",
    "\n",
    "Muestra el espacio disponible en HDFS. Con la opción -h muestra la información de un modo más legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                Size  Used  Available  Use%\n",
      "hdfs://localhost:9000  445.8 G    18    232.2 G    0%\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -df -h /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find  /ruta ... expresion\n",
    "\n",
    "Busca todos los ficheros que cumplan una determinada expresión. Si no se indica una ruta, la búsqueda se realiza a partir del directorio de trabajo.\n",
    "Con la opción -name se especifica el patrón a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ej_hdfs/file1.txt\n",
      "/ej_hdfs/file2.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -find /ej_hdfs -name \"file*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### help command\n",
    "\n",
    "Muestra información acerca del uso del comando que se especifique en command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ... :\n",
      "  Delete all files that match the specified file pattern. Equivalent to the Unix\n",
      "  command \"rm <src>\"\n",
      "                                                                                 \n",
      "  -f          If the file does not exist, do not display a diagnostic message or \n",
      "              modify the exit status to reflect an error.                        \n",
      "  -[rR]       Recursively deletes directories.                                   \n",
      "  -skipTrash  option bypasses trash, if enabled, and immediately deletes <src>.  \n",
      "  -safely     option requires safety confirmation, if enabled, requires          \n",
      "              confirmation before deleting large directory with more than        \n",
      "              <hadoop.shell.delete.limit.num.files> files. Delay is expected when\n",
      "              walking over large directory recursively to count the number of    \n",
      "              files to be deleted before the confirmation.                       \n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -help rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usage command\n",
    "    \n",
    "Es parecido al comando help, muestra información acerca de un comando pero de un modo más conciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: hadoop fs [generic options] -rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -usage rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios de práctica para desarrollar\n",
    "\n",
    "A continuación se presentan 11 ejercicios que el alumno debe desarrollar completamente, usando los comandos vistos anteriormente.  \n",
    "Insertar en cada celda el comando que realiza las acciones propuestas.\n",
    "\n",
    "Debajo de cada celda se muestra el resultado que se debería obtener en cada caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Crear dentro de /ej_hdfs un subdirectorio llamado subdir_1 y otro subdir_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/file2.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:45 /ej_hdfs/subdir_1\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:45 /ej_hdfs/subdir_2\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir -p /ej_hdfs/subdir_1\n",
    "! hdfs dfs -mkdir -p /ej_hdfs/subdir_2\n",
    "! hdfs dfs -ls /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crea un fichero de tamaño cero con nombre file1.txt en los dos subdirectorios creados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/file2.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_1\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_1/file1.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_2\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_2/file1.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -touchz /ej_hdfs/subdir_1/file1.txt\n",
    "! hdfs dfs -touchz /ej_hdfs/subdir_2/file1.txt\n",
    "! hdfs dfs -ls -R /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Mueve el fichero /ej_hdfs/file2.txt a subdir_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_1\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_1/file1.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:48 /ej_hdfs/subdir_2\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_2/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/subdir_2/file2.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mv /ej_hdfs/file2.txt /ej_hdfs/subdir_2/file2.txt\n",
    "! hdfs dfs -ls -R /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Copia el fichero /ej_hdfs/subdir_2/file2.txt a subdir_1 asignándole además un nuevo nombre file1_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:49 /ej_hdfs/subdir_1\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_1/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:49 /ej_hdfs/subdir_1/file1_1.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:48 /ej_hdfs/subdir_2\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_2/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/subdir_2/file2.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cp /ej_hdfs/subdir_2/file2.txt /ej_hdfs/subdir_1/file1_1.txt\n",
    "! hdfs dfs -ls -R /ej_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Obtiene desde hdfs información acerca del comando count. Luego haz un recuento del directorio  /ej_hdfs/subdir_1 de modo que muestre además una línea de cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] [-s] <path> ... :\n",
      "  Count the number of directories, files and bytes under the paths\n",
      "  that match the specified file pattern.  The output columns are:\n",
      "  DIR_COUNT FILE_COUNT CONTENT_SIZE PATHNAME\n",
      "  or, with the -q option:\n",
      "  QUOTA REM_QUOTA SPACE_QUOTA REM_SPACE_QUOTA\n",
      "        DIR_COUNT FILE_COUNT CONTENT_SIZE PATHNAME\n",
      "  The -h option shows file sizes in human readable format.\n",
      "  The -v option displays a header line.\n",
      "  The -x option excludes snapshots from being calculated. \n",
      "  The -t option displays quota by storage types.\n",
      "  It should be used with -q or -u option, otherwise it will be ignored.\n",
      "  If a comma-separated list of storage types is given after the -t option, \n",
      "  it displays the quota and usage for the specified types. \n",
      "  Otherwise, it displays the quota and usage for all the storage \n",
      "  types that support quota. The list of possible storage types(case insensitive):\n",
      "  ram_disk, ssd, disk and archive.\n",
      "  It can also pass the value '', 'all' or 'ALL' to specify all the storage types.\n",
      "  The -u option shows the quota and \n",
      "  the usage against the quota without the detailed content summary.The -e option\n",
      "  shows the erasure coding policy.The -s option shows snapshot counts.\n",
      "   DIR_COUNT   FILE_COUNT       CONTENT_SIZE PATHNAME\n",
      "           1            2                  7 /ej_hdfs/subdir_1\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -help count\n",
    "! hdfs dfs -count -v /ej_hdfs/subdir_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Muestra el espacio que ocupa cada fichero del directorio /ej_hdfs/subdir_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE  DISK_SPACE_CONSUMED_WITH_ALL_REPLICAS  FULL_PATH_NAME\n",
      "0     0                                      /ej_hdfs/subdir_2/file1.txt\n",
      "7     7                                      /ej_hdfs/subdir_2/file2.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -du -v /ej_hdfs/subdir_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Descarga al sistema local el archivo /ej_hdfs/subdir_2/file2.txt de modo que se guarde con el nombre file2_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36\n",
      "-rw-r--r-- 1 root root 22552 Oct 14 17:54 UD1-Actividad_Comandos_HDFS.ipynb\n",
      "-rw-r--r-- 1 root root     0 Oct 14 17:42 file1.txt\n",
      "-rw-r--r-- 1 root root     7 Oct 14 17:42 file2.txt\n",
      "-rw-r--r-- 1 root root     7 Oct 14 17:55 file2_2.txt\n",
      "drwxr-xr-x 1 1000 1000  4096 Oct 14 17:40 hadoop\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -get /ej_hdfs/subdir_2/file2.txt ./file2_2.txt\n",
    "! ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Añade la linea \"Subfile 2\" al archivo file2_2.txt recien creado. Luego súbelo al directorio /ej_hdfs/subdir_2 sin cambiar su nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_2/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:42 /ej_hdfs/subdir_2/file2.txt\n",
      "-rw-r--r--   1 root supergroup         17 2025-10-14 17:57 /ej_hdfs/subdir_2/file2_2.txt\n"
     ]
    }
   ],
   "source": [
    "! echo \"Subfile 2\" >> file2_2.txt\n",
    "! hdfs dfs -put ./file2_2.txt /ej_hdfs/subdir_2/file2_2.txt\n",
    "! hdfs dfs -ls /ej_hdfs/subdir_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Obtiene desde hdfs información acerca del uso del comando cat. Luego utilízalo para mostrar el contenido del fichero /ej_hdfs/subdir_2/file2_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-cat [-ignoreCrc] <src> ... :\n",
      "  Fetch all files that match the file pattern <src> and display their content on\n",
      "  stdout.\n",
      "File 2\n",
      "Subfile 2\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -help cat\n",
    "! hdfs dfs -cat /ej_hdfs/subdir_2/file2_2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Busca desde el directorio /ej_hdfs todos aquellos ficheros cuyo nombre cumpla el patrón file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ej_hdfs/file1.txt\n",
      "/ej_hdfs/subdir_1/file1.txt\n",
      "/ej_hdfs/subdir_1/file1_1.txt\n",
      "/ej_hdfs/subdir_2/file1.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -find /ej_hdfs -name \"file1*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Borra el directorio /ej_hdfs/subdir_2 incluyendo todo su contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /ej_hdfs/subdir_2\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:41 /ej_hdfs/file1.txt\n",
      "drwxr-xr-x   - root supergroup          0 2025-10-14 17:49 /ej_hdfs/subdir_1\n",
      "-rw-r--r--   1 root supergroup          0 2025-10-14 17:46 /ej_hdfs/subdir_1/file1.txt\n",
      "-rw-r--r--   1 root supergroup          7 2025-10-14 17:49 /ej_hdfs/subdir_1/file1_1.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /ej_hdfs/subdir_2\n",
    "! hdfs dfs -ls -R /ej_hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
