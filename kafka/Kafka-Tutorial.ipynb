{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea8b834-8446-4b3a-b59a-89de20cf8989",
   "metadata": {},
   "source": [
    "# Tutorial pr√°ctico de Apache Kafka (KRaft)\n",
    "\n",
    "## Introducci√≥n y preparaci√≥n del entorno\n",
    "\n",
    "En este cuaderno se utilizar√° un cl√∫ster de Apache Kafka desplegado mediante contenedores Docker,\n",
    "basado en la arquitectura **KRaft (Kafka Raft Metadata Mode)**, sin dependencia de ZooKeeper.\n",
    "\n",
    "Este apartado inicial tiene como finalidad **verificar que el entorno est√° correctamente configurado**\n",
    "y que podemos comunicarnos con el cl√∫ster Kafka.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb70f77-f260-49f6-a0b6-df4105d23ba3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Preparaci√≥n del entorno de trabajo\r\n",
    "\r\n",
    "El cuaderno utiliza Python para interactuar con Kafka mediante la librer√≠a\r\n",
    "**confluent-kafka**, un wrapper de alto rendimiento basado en *librdkafka*.\r\n",
    "\r\n",
    "Antes de comenzar, asumimos que:\r\n",
    "- El cl√∫ster Kafka est√° en ejecuci√≥n.\r\n",
    "- Jupyter tiene acceso a la red donde se encuentran los brokers.\r\n",
    "- La variable de entorno con los brokers est√° correctamente definida.\r\n",
    "\r\n",
    "En el siguiente bloque se importar√°n las librer√≠as necesarias\r\n",
    "y se comprobar√° la conectividad b√°sica con el cl√∫ster.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592eb31-0d84-4670-8415-f5f8b064cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En el caso que la librer√≠a no exista, hay que instalarla\n",
    "%pip install --upgrade confluent-kafka\n",
    "\n",
    "from confluent_kafka.admin import AdminClient\n",
    "from confluent_kafka import KafkaException\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb3b05-b30c-489b-b32a-6203690ac9e6",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de conexi√≥n al cl√∫ster\n",
    "\n",
    "Los brokers de Kafka se proporcionan mediante una variable de entorno,\n",
    "lo que permite desacoplar el c√≥digo del entorno f√≠sico donde se ejecuta.\n",
    "\n",
    "Esta aproximaci√≥n es habitual en entornos profesionales\n",
    "y facilita el despliegue del mismo c√≥digo en distintos escenarios\n",
    "(desarrollo, pruebas o producci√≥n).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29287cb7-87c2-4b67-a755-491bd555c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la lista de brokers desde la variable de entorno\n",
    "brokers = os.getenv(\"KAFKA_BROKERS\")\n",
    "\n",
    "if not brokers:\n",
    "    raise RuntimeError(\"No se ha definido la variable de entorno KAFKA_BROKERS\")\n",
    "\n",
    "print(f\"Brokers configurados: {brokers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af6e6f-06ea-42f2-80e4-d23f2e9c7496",
   "metadata": {},
   "source": [
    "### Comprobaci√≥n de conectividad con el cl√∫ster\n",
    "\n",
    "En este primer contacto con Kafka no se producir√°n ni consumir√°n mensajes.\n",
    "√önicamente se consultar√° la **metadata del cl√∫ster** para verificar que:\n",
    "\n",
    "- El cl√∫ster est√° accesible.\n",
    "- Los brokers responden correctamente.\n",
    "- Podemos obtener informaci√≥n b√°sica de la infraestructura.\n",
    "\n",
    "Este tipo de comprobaci√≥n es habitual como primer paso\n",
    "en cualquier aplicaci√≥n que vaya a interactuar con Kafka.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30f8fa-d749-4392-98e0-bd110e253a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient\n",
    "import os\n",
    "\n",
    "# Crear cliente administrativo\n",
    "admin_client = AdminClient({'bootstrap.servers': brokers})\n",
    "\n",
    "# Obtener metadatos completos del cl√∫ster\n",
    "cluster_metadata = admin_client.list_topics(timeout=10)\n",
    "\n",
    "print(\"=== Brokers del cl√∫ster ===\")\n",
    "for broker_id, broker in cluster_metadata.brokers.items():\n",
    "    print(f\"Broker ID: {broker_id}, Host: {broker.host}, Port: {broker.port}\")\n",
    "\n",
    "# Identificar el controller activo\n",
    "controller_id = cluster_metadata.controller_id\n",
    "controller = cluster_metadata.brokers[controller_id]\n",
    "\n",
    "print(\"\\n=== Controller activo ===\")\n",
    "print(f\"Broker ID: {controller_id}, Host: {controller.host}, Port: {controller.port}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ba285-c71b-47f8-902c-2b54cee8e2a5",
   "metadata": {},
   "source": [
    "### Observaci√≥n en Kafdrop\r\n",
    "\r\n",
    "Para complementar las acciones realizadas desde este cuaderno, utilizaremos **Kafdrop** como herramienta de exploraci√≥n visual del cl√∫ster Kafka.\r\n",
    "\r\n",
    "Kafdrop permite inspeccionar de forma gr√°fica y en tiempo real distintos elementos del cl√∫ster, como:\r\n",
    "- Brokers disponibles\r\n",
    "- Topics existentes\r\n",
    "- N√∫mero de particiones y factor de replicaci√≥n\r\n",
    "- L√≠deres de partici√≥n\r\n",
    "- Mensajes almacenados\r\n",
    "\r\n",
    "Durante el desarrollo de este tutorial, tras ejecutar los distintos fragmentos de c√≥digo en Python, se recomienda acceder a la interfaz web de Kafdrop para comprobar y analizar los efectos producidos sobre el cl√∫ster.\r\n",
    "\r\n",
    "La interfaz est√° disponible en la siguiente URL:\r\n",
    "\r\n",
    "üëâ **http://localhost:9000/**\r\n",
    "\r\n",
    "Esta observaci√≥n cruzada entre c√≥digo y visualizaci√≥n facilitar√° la comprensi√≥n de los conceptos te√≥ricos que se van introduciendo a lo largo de la sesi√≥n.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343431e-7fd0-4fac-a496-4a717d11a6ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Topics como entidad l√≥gica distribuida\n",
    "\n",
    "En Apache Kafka, un *topic* es una entidad l√≥gica que representa un flujo de datos. A diferencia de otros sistemas de mensajer√≠a, un topic **no es un recurso f√≠sico localizado en un √∫nico nodo**, sino una estructura distribuida a lo largo del cl√∫ster.\n",
    "\n",
    "Cada topic se divide en **particiones**, y cada partici√≥n se replica en uno o varios brokers. Esta arquitectura permite:\n",
    "\n",
    "- Escalar el procesamiento de datos de forma horizontal.\n",
    "- Garantizar tolerancia a fallos mediante replicaci√≥n.\n",
    "- Distribuir la carga de lectura y escritura entre distintos brokers.\n",
    "\n",
    "Desde el punto de vista del cliente (productores y consumidores), el topic se percibe como una √∫nica entidad l√≥gica, aunque internamente est√© repartido entre m√∫ltiples nodos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec415c-2906-4639-a8ce-111d1a0a51ed",
   "metadata": {},
   "source": [
    "### Particiones y r√©plicas\r\n",
    "\r\n",
    "Una **partici√≥n** es la unidad m√≠nima de paralelismo en Kafka. Cada partici√≥n tiene:\r\n",
    "\r\n",
    "- Un **l√≠der**, que gestiona las operaciones de lectura y escritura.\r\n",
    "- Una o varias **r√©plicas seguidoras**, que mantienen una copia sincronizada de los datos.\r\n",
    "\r\n",
    "Si el broker que aloja al l√≠der de una partici√≥n deja de estar disponible, Kafka puede **elegir autom√°ticamente un nuevo l√≠der** entre las r√©plicas disponibles, garantizando la continuidad del servicio.\r\n",
    "\r\n",
    "Este comportamiento ser√° observable m√°s adelante tanto desde el c√≥digo como desde la interfaz web de Kafdrop.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26e848-e181-45aa-bfad-ee454ece7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "import os\n",
    "\n",
    "# Configuraci√≥n de conexi√≥n\n",
    "brokers = os.environ.get(\n",
    "    \"KAFKA_BROKERS\",\n",
    "    \"kafka1:9092,kafka2:9094,kafka3:9096,kafka4:9098\"\n",
    ")\n",
    "\n",
    "admin_client = AdminClient({'bootstrap.servers': brokers})\n",
    "\n",
    "# Definici√≥n del topic\n",
    "topic_name = \"demo-topic-distribuido\"\n",
    "\n",
    "new_topic = NewTopic(\n",
    "    topic=topic_name,\n",
    "    num_partitions=3,\n",
    "    replication_factor=2\n",
    ")\n",
    "\n",
    "# Creaci√≥n del topic\n",
    "fs = admin_client.create_topics([new_topic])\n",
    "\n",
    "for topic, future in fs.items():\n",
    "    try:\n",
    "        future.result()\n",
    "        print(f\"Topic '{topic}' creado correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear el topic '{topic}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee86dda-e1cf-48f2-9ac5-8967abf09da0",
   "metadata": {},
   "source": [
    "El topic creado tiene las siguientes caracter√≠sticas:\r\n",
    "\r\n",
    "- **3 particiones**, lo que permite paralelizar la producci√≥n y el consumo.\r\n",
    "- **Factor de replicaci√≥n 2**, lo que implica que cada partici√≥n estar√° presente en dos brokers distintos.\r\n",
    "\r\n",
    "A partir de este momento, el topic existe f√≠sicamente repartido entre varios brokers del cl√∫ster. Cada partici√≥n tendr√° un broker l√≠der asignado autom√°ticamente por Kafka.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce07a8a-0753-4b79-a8ea-40344a9e5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener metadatos del topic creado\n",
    "metadata = admin_client.list_topics(timeout=10)\n",
    "\n",
    "topic_metadata = metadata.topics[topic_name]\n",
    "\n",
    "print(f\"=== Detalle del topic '{topic_name}' ===\")\n",
    "\n",
    "for partition_id, partition in topic_metadata.partitions.items():\n",
    "    print(\n",
    "        f\"Partici√≥n {partition_id} | \"\n",
    "        f\"L√≠der: {partition.leader} | \"\n",
    "        f\"R√©plicas: {partition.replicas} | \"\n",
    "        f\"ISR: {partition.isrs}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a5fb8-9d9d-4e5c-b567-eb628ef2a776",
   "metadata": {},
   "source": [
    "En la salida anterior se puede observar:\n",
    "\n",
    "- El **broker l√≠der** de cada partici√≥n.\n",
    "- La lista de **r√©plicas** asignadas.\n",
    "- El conjunto ISR (*In-Sync Replicas*), que indica qu√© r√©plicas est√°n correctamente sincronizadas.\n",
    "\n",
    "Estos valores pueden cambiar din√°micamente si un broker deja de estar disponible o se reincorpora al cl√∫ster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc388f-dc1c-478b-b3ed-adf674c7a4bd",
   "metadata": {},
   "source": [
    "### Observaci√≥n en Kafdrop\n",
    "\n",
    "Accede a la interfaz web de Kafdrop:\n",
    "\n",
    "http://localhost:9000/\n",
    "\n",
    "Dentro del topic `demo-topic-distribuido`, revisa:\n",
    "\n",
    "- El n√∫mero de particiones.\n",
    "- Qu√© broker act√∫a como l√≠der de cada partici√≥n.\n",
    "- C√≥mo se distribuyen las r√©plicas entre los distintos brokers.\n",
    "\n",
    "Contrasta esta informaci√≥n con la obtenida mediante el c√≥digo Python para reforzar la comprensi√≥n del car√°cter distribuido de los topics en Kafka.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43696b9-4a13-45fe-a103-ec61e0badad7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Productores: introducci√≥n al env√≠o de mensajes en Kafka\r\n",
    "\r\n",
    "Hasta ahora hemos analizado Kafka desde un punto de vista estructural: el cl√∫ster, los brokers y los topics.\r\n",
    "En este apartado damos el siguiente paso natural: **empezar a generar datos reales**.\r\n",
    "\r\n",
    "Un **productor** es el componente encargado de enviar mensajes a Kafka.  \r\n",
    "Desde el punto de vista del cliente, Kafka act√∫a como un sistema distribuido capaz de:\r\n",
    "\r\n",
    "- recibir mensajes de forma concurrente,\r\n",
    "- almacenarlos de manera tolerante a fallos,\r\n",
    "- y distribuirlos entre los brokers del cl√∫ster.\r\n",
    "\r\n",
    "En este primer contacto trabajaremos con productores de forma **intencionalmente sencilla**, centr√°ndonos √∫nicamente en:\r\n",
    "- enviar mensajes de texto,\r\n",
    "- verificar su llegada al cl√∫ster,\r\n",
    "- observar el resultdos posteriores.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc35403-47b8-4611-b137-904c3ca2a883",
   "metadata": {},
   "source": [
    "### Conceptos clave del productor\n",
    "\n",
    "Antes de pasar al c√≥digo, conviene fijar algunos conceptos b√°sicos:\n",
    "\n",
    "- Un productor **no env√≠a mensajes a un broker concreto**, sino a un *topic*.\n",
    "- Kafka se encarga internamente de decidir:\n",
    "  - a qu√© partici√≥n se asigna el mensaje,\n",
    "  - en qu√© broker se almacena.\n",
    "- El env√≠o de mensajes es **as√≠ncrono** por defecto.\n",
    "- El productor recibe confirmaci√≥n de que el mensaje ha sido aceptado por el cl√∫ster.\n",
    "\n",
    "En este punto del tutorial asumimos:\n",
    "- un cl√∫ster Kafka ya operativo,\n",
    "- al menos un topic existente,\n",
    "- acceso al cl√∫ster mediante la librer√≠a `confluent-kafka` desde Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c122e23-337e-435e-ace3-d24cda71ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import socket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461a3b2-516f-474f-8416-f402e0856232",
   "metadata": {},
   "source": [
    "### Configuraci√≥n b√°sica del productor\n",
    "\n",
    "Para crear un productor necesitamos, como m√≠nimo, indicar:\n",
    "- la lista de brokers del cl√∫ster (bootstrap servers),\n",
    "- un identificador de cliente.\n",
    "\n",
    "No es necesario especificar particiones ni brokers concretos.\n",
    "Kafka se encarga de la distribuci√≥n interna de los mensajes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4ec12-365a-4416-a9e8-badc5d76f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"bootstrap.servers\": \"kafka1:9092,kafka2:9094,kafka3:9096,kafka4:9098\",\n",
    "    \"client.id\": socket.gethostname()\n",
    "}\n",
    "\n",
    "producer = Producer(conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3893f0-d07a-4d67-961d-5d8a3afed8e7",
   "metadata": {},
   "source": [
    "### Env√≠o de un primer mensaje\n",
    "\n",
    "Vamos a enviar un mensaje simple de texto a un topic existente.\n",
    "En este ejemplo utilizaremos un topic previamente creado en el cl√∫ster.\n",
    "\n",
    "Tras ejecutar el c√≥digo:\n",
    "- el mensaje ser√° enviado a Kafka,\n",
    "- podremos comprobar su llegada desde la interfaz web de Kafdrop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986cd13-9100-4f87-a6a0-6bd7eedd8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = \"demo-topic\"\n",
    "\n",
    "producer.produce(\n",
    "    topic=topic_name,\n",
    "    value=\"Primer mensaje enviado desde un productor en Python\"\n",
    ")\n",
    "\n",
    "producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69315408-5278-409b-8a01-73780603a45f",
   "metadata": {},
   "source": [
    "### Observaci√≥n en Kafdrop\r\n",
    "\r\n",
    "Accede a la interfaz web de Kafdrop para comprobar el resultado del env√≠o:\r\n",
    "\r\n",
    "http://localhost:9000/\r\n",
    "\r\n",
    "Desde Kafdrop puedes:\r\n",
    "- localizar el topic utilizado,\r\n",
    "- visualizar los mensajes almacenados,\r\n",
    "- comprobar en qu√© partici√≥n se ha escrito elter Kafka.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede70b1d-b2cc-4131-b132-e8da8c324f54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. El mensaje en Kafka: clave, valor y distribuci√≥n\r\n",
    "\r\n",
    "Hasta este punto del tutorial hemos trabajado con el cl√∫ster, los brokers y los topics como entidades distribuidas.\r\n",
    "El siguiente paso natural es entender **qu√© es realmente un mensaje en Kafka** y c√≥mo su estructura influye directamente en el\r\n",
    "comportamiento del sistema.\r\n",
    "\r\n",
    "En Kafka, un mensaje no es solo un ‚Äúdato que se env√≠a‚Äù, sino una unidad que:\r\n",
    "- se almacena en una partici√≥n concreta,\r\n",
    "- sigue reglas de orden,\r\n",
    "- y participa en mecanismos de escalabilidad y tolerancia a fallos.\r\n",
    "\r\n",
    "En este apartado nos centraremos en dos elementos clave del mensaje:\r\n",
    "- **key (clave)**\r\n",
    "- **value (valor)**\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7f145-dc5e-44cb-a6ae-9f70a686bc52",
   "metadata": {},
   "source": [
    "### Estructura b√°sica de un mensaje Kafka\n",
    "\n",
    "Conceptualmente, un mensaje Kafka puede representarse como:\n",
    "\n",
    "- **key**: valor opcional que Kafka utiliza para decidir la partici√≥n destino.\n",
    "- **value**: el contenido del mensaje (texto, binario, JSON, CSV, etc.).\n",
    "- **offset**: posici√≥n del mensaje dentro de la partici√≥n (asignado por Kafka).\n",
    "- **timestamp**: marca temporal asociada al mensaje.\n",
    "\n",
    "En este bloque nos centraremos en la relaci√≥n entre **key**, **particiones** y **orden**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75df6e-cb0c-4679-9893-23979981a0ca",
   "metadata": {},
   "source": [
    "### Clave y particionado\n",
    "\n",
    "Kafka distribuye los mensajes de un topic entre sus particiones siguiendo estas reglas generales:\n",
    "\n",
    "- **Mensajes sin clave**  \n",
    "  Kafka distribuye los mensajes entre las particiones disponibles de forma autom√°tica.\n",
    "  El objetivo es equilibrar la carga.\n",
    "\n",
    "- **Mensajes con clave**  \n",
    "  Kafka calcula un hash de la clave y siempre env√≠a los mensajes con la misma clave\n",
    "  a la **misma partici√≥n**.\n",
    "\n",
    "Esto implica dos consecuencias importantes:\n",
    "- El orden **solo est√° garantizado dentro de una partici√≥n**.\n",
    "- La clave es una herramienta fundamental para controlar el orden l√≥gico de los mensajes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365243e-b5ae-4de6-9c81-969a2f8cf5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import time\n",
    "\n",
    "brokers = \"kafka1:9092,kafka2:9094,kafka3:9096,kafka4:9098\"\n",
    "topic = \"demo-topic-distribuido\"\n",
    "\n",
    "producer = Producer({\n",
    "    \"bootstrap.servers\": brokers\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa646ac-c518-4627-afe4-8ed3416fa776",
   "metadata": {},
   "source": [
    "### Env√≠o de mensajes sin clave\n",
    "\n",
    "Vamos a enviar varios mensajes **sin clave** al mismo topic.\n",
    "Kafka decidir√° autom√°ticamente a qu√© partici√≥n va cada uno.\n",
    "\n",
    "Despu√©s de ejecutar la celda, observa el resultado en Kafdrop:\n",
    "- topic `demo-topic-distribuido`\n",
    "- pesta√±a *Topics ‚Üí Partitions*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eac050-8297-4fab-9771-b18305b69346",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    producer.produce(\n",
    "        topic=topic,\n",
    "        value=f\"Mensaje sin clave {i}\"\n",
    "    )\n",
    "\n",
    "producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6aed11-14ae-49eb-95b5-673ca10bf138",
   "metadata": {},
   "source": [
    "### Observaci√≥n en Kafdrop\n",
    "\n",
    "Accede a la interfaz web de Kafdrop:\n",
    "\n",
    "http://localhost:9000/\n",
    "\n",
    "Observa:\n",
    "- c√≥mo los mensajes se reparten entre distintas particiones,\n",
    "- que no existe una relaci√≥n directa entre el contenido del mensaje y la partici√≥n.\n",
    "\n",
    "Esto es un comportamiento normal cuando **no se define clave**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44673e9b-37d6-4f1a-b9ff-3927a49fbd15",
   "metadata": {},
   "source": [
    "### Env√≠o de mensajes con clave\n",
    "\n",
    "Ahora enviaremos mensajes **con la misma clave**.\n",
    "El objetivo es comprobar que Kafka los dirige siempre a la misma partici√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc769a5b-6955-4532-bd4f-5b41581263d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    producer.produce(\n",
    "        topic=topic,\n",
    "        key=\"usuario-123\",\n",
    "        value=f\"Mensaje con clave usuario-123 #{i}\"\n",
    "    )\n",
    "\n",
    "producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0c506-a370-4f24-8b44-552d72177395",
   "metadata": {},
   "source": [
    "### Observaci√≥n del efecto de la clave\r\n",
    "\r\n",
    "En Kafdrop, revisa nuevamente las particiones del topic.\r\n",
    "\r\n",
    "Deber√≠as observar que:\r\n",
    "- todos los mensajes con la clave `usuario-123` est√°n en la **misma partici√≥n**,\r\n",
    "- el orden de los mensajes se mantiene dentro de esa partici√≥n.\r\n",
    "\r\n",
    "Esto ilustra una regla fundamental de Kafka:\r\n",
    "> El orden est√° garantizado por partici√≥n, no por topic.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a2e71-4ffe-4488-a47d-6dc739254c68",
   "metadata": {},
   "source": [
    "### M√∫ltiples claves, m√∫ltiples flujos\n",
    "\n",
    "Por √∫ltimo, enviaremos mensajes con **claves distintas** para simular varios flujos de datos independientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a696c9-5c07-4496-b857-ffa40b00854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "claves = [\"cliente-A\", \"cliente-B\", \"cliente-C\"]\n",
    "\n",
    "for clave in claves:\n",
    "    for i in range(5):\n",
    "        producer.produce(\n",
    "            topic=topic,\n",
    "            key=clave,\n",
    "            value=f\"Evento {i} para {clave}\"\n",
    "        )\n",
    "\n",
    "producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c1229-99d9-41ed-aa2d-64564568e674",
   "metadata": {},
   "source": [
    "### Qu√© debe quedar claro tras este apartado\r\n",
    "\r\n",
    "- La clave no es obligatoria, pero **s√≠ estrat√©gica**.\r\n",
    "- Kafka no garantiza orden global, solo **orden por partici√≥n**.\r\n",
    "- Elegir bien la clave impacta directamente en:\r\n",
    "  - escalabilidad,\r\n",
    "  - orden,\r\n",
    "  - dise√±o de consumidores.\r\n",
    "\r\n",
    "Estos conceptos ser√°n fundamentales cuando pasemos a:\r\n",
    "- consumidores,\r\n",
    "- procesamiento paralelo,\r\n",
    "- y dise√±o de aplicaciones reales con Kafka.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1846b5-482e-4638-8faf-4a63aaa795c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. El consumidor en Kafka\r\n",
    "\r\n",
    "Hasta ahora hemos visto c√≥mo se producen mensajes y c√≥mo estos se distribuyen en el cl√∫ster.\r\n",
    "El siguiente elemento clave es el **consumidor**, responsable de leer los mensajes almacenados en los topics.\r\n",
    "\r\n",
    "En Kafka, consumir no significa ‚Äúrecibir un mensaje y borrarlo‚Äù, sino:\r\n",
    "- leer mensajes de una partici√≥n,\r\n",
    "- mantener la posici√≥n de lectura (offset),\r\n",
    "- y coordinarse con otros consumidores cuando trabajan en grupo.\r\n",
    "\r\n",
    "Este apartado se centrar√° en:\r\n",
    "- c√≥mo se leen los mensajes,\r\n",
    "- qu√© es un offset,\r\n",
    "- y c√≥mo Kafka gestiona el consumo distribuido.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea49eb4-cc22-40f9-9939-43ac2c656ef0",
   "metadata": {},
   "source": [
    "### Conceptos b√°sicos del consumo\n",
    "\n",
    "Al consumir mensajes en Kafka debemos tener claros los siguientes conceptos:\n",
    "\n",
    "- **Offset**  \n",
    "  Es la posici√≥n de lectura dentro de una partici√≥n.\n",
    "  Kafka no borra los mensajes cuando se consumen; el consumidor simplemente avanza su offset.\n",
    "\n",
    "- **Lectura secuencial**  \n",
    "  Los mensajes se leen en orden dentro de cada partici√≥n.\n",
    "\n",
    "- **Estado del consumidor**  \n",
    "  Kafka guarda el offset asociado a un consumidor (o grupo) para saber por d√≥nde continuar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd286018-08c9-48f4-b19f-af6388b61310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dae3a7-4fd5-4c5a-a25d-3eafc05ee4b0",
   "metadata": {},
   "source": [
    "### Configuraci√≥n b√°sica de un consumidor\n",
    "\n",
    "Vamos a crear un consumidor sencillo que:\n",
    "- se conecte al cl√∫ster,\n",
    "- lea mensajes de un topic,\n",
    "- y muestre su contenido por pantalla.\n",
    "\n",
    "En este primer ejemplo no usaremos grupos complejos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695f32e-2119-4532-b9a9-b8a8019c00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "brokers = \"kafka1:9092,kafka2:9094,kafka3:9096,kafka4:9098\"\n",
    "topic = \"demo-topic-distribuido\"\n",
    "\n",
    "consumer_conf = {\n",
    "    \"bootstrap.servers\": brokers,\n",
    "    \"group.id\": \"grupo-demo\",\n",
    "    \"auto.offset.reset\": \"earliest\"\n",
    "}\n",
    "\n",
    "consumer = Consumer(consumer_conf)\n",
    "consumer.subscribe([topic])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66908027-4e5b-48a0-a0f5-3fd1e80ee0c1",
   "metadata": {},
   "source": [
    "### Lectura de mensajes\n",
    "\n",
    "A continuaci√≥n leeremos mensajes del topic.\n",
    "Observa que:\n",
    "- el consumidor va leyendo mensajes uno a uno,\n",
    "- cada mensaje pertenece a una partici√≥n concreta,\n",
    "- y tiene un offset asociado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082c5e1-793f-4d6c-a2ce-c15b0cbf3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Leyendo mensajes...\")\n",
    "\n",
    "for _ in range(10):\n",
    "    msg = consumer.poll(1.0)\n",
    "\n",
    "    if msg is None:\n",
    "        continue\n",
    "\n",
    "    if msg.error():\n",
    "        print(f\"Error: {msg.error()}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Partici√≥n: {msg.partition()} | \"\n",
    "            f\"Offset: {msg.offset()} | \"\n",
    "            f\"Clave: {msg.key()} | \"\n",
    "            f\"Valor: {msg.value().decode('utf-8')}\"\n",
    "        )\n",
    "\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84061c6c-99cf-4ed6-a16c-85c1a2bb4b56",
   "metadata": {},
   "source": [
    "### Observaci√≥n en Kafdrop\r\n",
    "\r\n",
    "Mientras el consumidor est√° activo o despu√©s de ejecutar la celda, revisa en Kafdrop:\r\n",
    "\r\n",
    "http://localhost:9000/\r\n",
    "\r\n",
    "Observa:\r\n",
    "- el n√∫mero de mensajes en cada partici√≥n,\r\n",
    "- c√≥mo el offset va avanzando,\r\n",
    "- que los mensajes no se eliminan tras ser consumidos.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af6f37-da23-4184-b287-feb58962063a",
   "metadata": {},
   "source": [
    "### El offset y la relectura de mensajes\n",
    "\n",
    "El valor `auto.offset.reset` controla desde d√≥nde empieza a leer un consumidor cuando\n",
    "no existe un offset previo guardado:\n",
    "\n",
    "- **earliest**: desde el primer mensaje disponible.\n",
    "- **latest**: solo mensajes nuevos a partir de ese momento.\n",
    "\n",
    "Este comportamiento es clave para:\n",
    "- pruebas,\n",
    "- reprocesamiento,\n",
    "- y depuraci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9e749-2156-49a4-be3c-ab95e4db8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo alternativo: comenzar desde los mensajes m√°s recientes\n",
    "\n",
    "consumer_conf_latest = {\n",
    "    \"bootstrap.servers\": brokers,\n",
    "    \"group.id\": \"grupo-demo-latest\",\n",
    "    \"auto.offset.reset\": \"latest\"\n",
    "}\n",
    "\n",
    "consumer_latest = Consumer(consumer_conf_latest)\n",
    "consumer_latest.subscribe([topic])\n",
    "\n",
    "msg = consumer_latest.poll(2.0)\n",
    "\n",
    "if msg is None:\n",
    "    print(\"No hay mensajes nuevos\")\n",
    "elif msg.error():\n",
    "    print(f\"Error: {msg.error()}\")\n",
    "else:\n",
    "    print(f\"Mensaje recibido: {msg.value().decode('utf-8')}\")\n",
    "\n",
    "consumer_latest.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961304b-1842-42cf-bc89-d986b599cdaf",
   "metadata": {},
   "source": [
    "### Qu√© debe quedar claro tras este apartado\n",
    "\n",
    "- Kafka no borra los mensajes al consumirlos.\n",
    "- El consumidor controla su progreso mediante offsets.\n",
    "- El orden est√° garantizado dentro de cada partici√≥n.\n",
    "- El comportamiento del consumidor depende de su configuraci√≥n.\n",
    "\n",
    "En el siguiente apartado daremos un paso m√°s:\n",
    "veremos c√≥mo **varios consumidores pueden trabajar juntos** mediante grupos de consumo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f8773-7b2b-4ae3-9dc7-f3bd80efef91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Grupos de consumidores y consumo distribuido\r\n",
    "\r\n",
    "Hasta ahora hemos trabajado con un √∫nico consumidor leyendo mensajes de un topic.\r\n",
    "Sin embargo, uno de los pilares de Kafka es la **lectura paralela y escalable** de datos.\r\n",
    "\r\n",
    "Esto se consigue mediante los **grupos de consumidores** (consumer groups).\r\n",
    "\r\n",
    "Un grupo de consumidores permite:\r\n",
    "- repartir las particiones de un topic entre varios consumidores,\r\n",
    "- escalar horizontalmente el procesamiento,\r\n",
    "- garantizar que cada mensaje sea procesado una sola vez por grupo.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda2d73-a2da-4bf6-a42b-b14cb180b64b",
   "metadata": {},
   "source": [
    "### Conceptos clave\n",
    "\n",
    "Antes de pasar a la pr√°ctica, conviene fijar algunos conceptos:\n",
    "\n",
    "- **Consumer Group**  \n",
    "  Conjunto de consumidores que comparten un mismo `group.id`.\n",
    "\n",
    "- **Asignaci√≥n de particiones**  \n",
    "  Kafka asigna cada partici√≥n de un topic a un √∫nico consumidor dentro del grupo.\n",
    "\n",
    "- **Paralelismo real**  \n",
    "  El paralelismo m√°ximo est√° limitado por el n√∫mero de particiones, no por el n√∫mero de consumidores.\n",
    "\n",
    "Si hay m√°s consumidores que particiones, algunos consumidores quedar√°n inactivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca4111b-2a8c-4fb2-9ff0-c066acb18b49",
   "metadata": {},
   "source": [
    "### Escenario de prueba\n",
    "\n",
    "Para este apartado se asume:\n",
    "- un topic con varias particiones,\n",
    "- mensajes ya existentes en el topic,\n",
    "- y varios consumidores que se lanzan con el mismo `group.id`.\n",
    "\n",
    "El objetivo es observar c√≥mo Kafka reparte el trabajo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f09f0-a914-4c0c-b484-2b7855fe98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc8609-119f-4e3d-aa16-1c5ad888eef1",
   "metadata": {},
   "source": [
    "### Consumidor A (miembro del grupo)\r\n",
    "\r\n",
    "Este ser√° el primer consumidor del grupo.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05461cef-3e67-4f69-a3bd-f25fcea74304",
   "metadata": {},
   "outputs": [],
   "source": [
    "brokers = \"kafka1:9092,kafka2:9094,kafka3:9096,kafka4:9098\"\n",
    "topic = \"demo-topic-distribuido\"\n",
    "\n",
    "consumer_a_conf = {\n",
    "    \"bootstrap.servers\": brokers,\n",
    "    \"group.id\": \"grupo-distribuido\",\n",
    "    \"auto.offset.reset\": \"earliest\"\n",
    "}\n",
    "\n",
    "consumer_a = Consumer(consumer_a_conf)\n",
    "consumer_a.subscribe([topic])\n",
    "\n",
    "print(\"Consumidor A activo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95e97b-9d21-4108-82b9-bbb4d745fdeb",
   "metadata": {},
   "source": [
    "### Consumidor B (mismo grupo)\n",
    "\n",
    "Este segundo consumidor pertenece al mismo grupo.\n",
    "Kafka redistribuir√° autom√°ticamente las particiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023dd53-b1e4-48e1-a382-b1c3869b6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_b_conf = {\n",
    "    \"bootstrap.servers\": brokers,\n",
    "    \"group.id\": \"grupo-distribuido\",\n",
    "    \"auto.offset.reset\": \"earliest\"\n",
    "}\n",
    "\n",
    "consumer_b = Consumer(consumer_b_conf)\n",
    "consumer_b.subscribe([topic])\n",
    "\n",
    "print(\"Consumidor B activo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015326eb-8902-47b5-967e-2897fa4ac9ce",
   "metadata": {},
   "source": [
    "### Lectura simult√°nea desde ambos consumidores\n",
    "\n",
    "Ejecuta esta celda en cada consumidor (A y B) y observa:\n",
    "\n",
    "- qu√© particiones procesa cada uno,\n",
    "- c√≥mo no se duplican los mensajes,\n",
    "- y c√≥mo el reparto depende del n√∫mero de particiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8d03c-8e61-444d-9d75-b3e1578d0b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_mensajes(consumer, nombre):\n",
    "    print(f\"Leyendo mensajes para: {nombre}\")\n",
    "    for _ in range(5):\n",
    "        msg = consumer.poll(1.0)\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "\n",
    "        if msg.error():\n",
    "            print(f\"{nombre} - Error: {msg.error()}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"{nombre} | \"\n",
    "                f\"Partici√≥n: {msg.partition()} | \"\n",
    "                f\"Offset: {msg.offset()} | \"\n",
    "                f\"Valor: {msg.value().decode('utf-8')}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea2075-7cc9-458e-8544-06ba3130cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura desde el consumidor A\n",
    "leer_mensajes(consumer_a, \"Consumidor A\")\n",
    "consumer_a.close()\n",
    "\n",
    "# Lectura desde el consumidor B\n",
    "leer_mensajes(consumer_b, \"Consumidor B\")\n",
    "consumer_b.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba49978-9ced-4f4a-85af-6c7f7f0cc2ef",
   "metadata": {},
   "source": [
    "### Rebalanceo de consumidores\n",
    "\n",
    "Kafka gestiona autom√°ticamente los cambios en el grupo:\n",
    "\n",
    "- si un consumidor se detiene,\n",
    "- si se a√±ade uno nuevo,\n",
    "- o si cambia el n√∫mero de particiones.\n",
    "\n",
    "Este proceso se llama **rebalanceo**.\n",
    "\n",
    "Durante el rebalanceo:\n",
    "- las particiones se reasignan,\n",
    "- los consumidores pausan moment√°neamente la lectura,\n",
    "- y luego contin√∫an desde el offset correcto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d3cb9-4f5e-4fce-9086-14b57d75251a",
   "metadata": {},
   "source": [
    "### Observaci√≥n en Kafdrop\n",
    "\n",
    "Accede a:\n",
    "\n",
    "http://localhost:9000/\n",
    "\n",
    "Observa:\n",
    "- el n√∫mero de particiones del topic,\n",
    "- el l√≠der de cada partici√≥n,\n",
    "- y c√≥mo el consumo se distribuye entre consumidores.\n",
    "\n",
    "Aunque Kafdrop no muestra directamente los grupos,\n",
    "s√≠ permite razonar sobre el reparto observado en el c√≥digo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf48af-3cb3-441b-b54a-b6edf696e9c4",
   "metadata": {},
   "source": [
    "### Qu√© debe quedar claro tras este apartado\n",
    "\n",
    "- Un grupo de consumidores permite escalar el procesamiento.\n",
    "- Cada partici√≥n solo puede ser consumida por un consumidor del grupo.\n",
    "- El paralelismo depende del n√∫mero de particiones.\n",
    "- Kafka gestiona autom√°ticamente fallos y redistribuciones.\n",
    "\n",
    "Con esto se completa el ciclo b√°sico:\n",
    "topic ‚Üí particiones ‚Üí productor ‚Üí mensajes ‚Üí consumidor ‚Üí grupo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367af23-5b7f-4723-b073-3a712807b6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
