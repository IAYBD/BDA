{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63228d27",
   "metadata": {},
   "source": [
    "# Pr√°ctica de MapReduce sobre dataset de Juegos en Red\n",
    "\n",
    "Este cuaderno contiene los ejercicios pr√°cticos para aplicar patrones MapReduce sobre un dataset de sesiones de juegos online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5100b-ceec-4829-9cd0-0c048a087844",
   "metadata": {},
   "source": [
    "## **Alumno:** Rafael Navarro G√≥mez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c16422",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Configuraci√≥n inicial del entorno Hadoop\n",
    "\n",
    "> **Nota importante:**\n",
    "> Antes de comenzar cada ejercicio, **cambia el valor de la variable `NAME_E`** para asignarle un nombre identificativo (por ejemplo: `01_wordcount`, `02_avg_duration`, etc.).\n",
    "> Esto permitir√° que **cada ejercicio se ejecute en un subdirectorio diferente dentro de HDFS**, evitando conflictos y conservando los resultados anteriores.\n",
    "> Tras modificar `NAME_E`, **vuelve a ejecutar esta celda completa** para que se actualicen las rutas y variables del entorno.\n",
    "> ‚ö†Ô∏è No modifiques las dem√°s variables a menos que se indique expresamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c1eb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MATERIALES=/home/jovyan/work/materiales\n",
      "env: HDFS_IN=/user/shared/05\n",
      "env: HDFS_OUT=/user/shared/05/salida\n",
      "env: LOCAL_IN=/home/jovyan/work/user/shared/05\n",
      "env: LOCAL_OUT=/home/jovyan/work/user/shared/05/salida\n",
      "/home/jovyan/work/user/shared/05\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üß© CONFIGURACI√ìN DEL ENTORNO DE TRABAJO PARA MAPREDUCE\n",
    "# ==========================================================\n",
    "\n",
    "# üîπ Nombre del ejercicio actual (personalizable para cada enunciado)\n",
    "NAME_E = '05'\n",
    "\n",
    "# üîπ Directorio base de trabajo local en Jupyter\n",
    "WORK_DIR = '/home/jovyan/work'\n",
    "\n",
    "# üîπ Carpeta donde se encuentran los materiales proporcionados\n",
    "MATERIALES = f'{WORK_DIR}/materiales'\n",
    "\n",
    "# üîπ Directorios de entrada y salida en HDFS\n",
    "HDFS_BASE = '/user/shared'\n",
    "HDFS_IN = f'{HDFS_BASE}/{NAME_E}'\n",
    "HDFS_OUT = f'{HDFS_BASE}/{NAME_E}/salida'\n",
    "\n",
    "# üîπ Directorios locales equivalentes para trabajar temporalmente\n",
    "LOCAL_IN = f'{WORK_DIR}{HDFS_IN}'\n",
    "LOCAL_OUT = f'{WORK_DIR}{HDFS_OUT}'\n",
    "\n",
    "# ==========================================================\n",
    "# Declaraci√≥n de variables de entorno para Hadoop y shell\n",
    "# ==========================================================\n",
    "%env MATERIALES=$MATERIALES\n",
    "%env HDFS_IN=$HDFS_IN\n",
    "%env HDFS_OUT=$HDFS_OUT\n",
    "%env LOCAL_IN=$LOCAL_IN\n",
    "%env LOCAL_OUT=$LOCAL_OUT\n",
    "\n",
    "# Creamos los directorios locales necesarios (si no existen)\n",
    "!mkdir -p $LOCAL_IN\n",
    "\n",
    "# Cambiamos el directorio de trabajo actual\n",
    "%cd $LOCAL_IN\n",
    "\n",
    "# ==========================================================\n",
    "# üßπ (Opcional) Limpieza de ejecuciones previas en HDFS\n",
    "# ==========================================================\n",
    "# ‚ö†Ô∏è Descomenta la siguiente l√≠nea si necesitas eliminar resultados anteriores\n",
    "# ! hdfs dfs -rm -r -f $HDFS_IN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef45e737",
   "metadata": {},
   "source": [
    "### üìÇ Carga del dataset\n",
    "\n",
    "Sube el archivo **`game_sessions_1Mi.csv`** que se proporciona junto a este notebook al entorno de Jupyter usando el bot√≥n de `Upload`.  \n",
    "Una vez subido, comprueba que se muestra en el directorio de trabajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229dcba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Contenido de la carpeta de materiales:\n",
      "total 35204\n",
      "-rw-r--r-- 1 jovyan users 36047049 Nov 20 18:32 game_sessions_1Mi.csv\n",
      "\n",
      "üìÅ Copiar el dataset en HDFS para que est√© disponible en todos los ejercicios:\n",
      "put: `/user/shared/game_sessions_1Mi.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "!echo 'üìÅ Contenido de la carpeta de materiales:'\n",
    "!ls -l $MATERIALES\n",
    "!echo ''\n",
    "!echo 'üìÅ Copiar el dataset en HDFS para que est√© disponible en todos los ejercicios:'\n",
    "! hdfs dfs -put $MATERIALES/game_sessions_1Mi.csv $HDFS_BASE/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a106b",
   "metadata": {},
   "source": [
    "### üìä Introducci√≥n al dataset\n",
    "\n",
    "El dataset `game_sessions_1Mi.csv` contiene registros de sesiones de juegos online.  \n",
    "Cada fila representa una partida individual de un usuario, incluyendo informaci√≥n sobre:\n",
    "- T√≠tulo del juego (`game_title`)\n",
    "- Regi√≥n del jugador (`region`)\n",
    "- Plataforma utilizada (`platform`)\n",
    "- Duraci√≥n de la sesi√≥n (`session_duration_min`)\n",
    "- Puntuaci√≥n obtenida (`score`)\n",
    "- Objetos recolectados (`items_collected`)\n",
    "- Resultado del equipo o jugador (`team_result`)\n",
    "\n",
    "Este dataset se usar√° para aplicar distintos patrones MapReduce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d273c",
   "metadata": {},
   "source": [
    "### üß© Bloque de ejercicios pr√°cticos\n",
    "\n",
    "> **Indicaciones generales:**\n",
    "> - En cada ejercicio, muestra **el c√≥digo completo de Mapper y Reducer** y los **resultados de la ejecuci√≥n**.\n",
    "> - Puedes a√±adir celdas auxiliares para comprobaciones intermedias.\n",
    "> - Cada ejercicio se ejecutar√° en un **subdirectorio independiente en HDFS**.\n",
    "> - Incluye siempre una **celda final de verificaci√≥n de resultados en HDFS** al final de cada ejercicio.\n",
    "> - Las celdas con errores de ejecuci√≥n o salidas incompletas ser√°n penalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b614d",
   "metadata": {},
   "source": [
    "### Ejercicio 1 ‚Äì Conteo de sesiones por juego\n",
    "\n",
    "En este ejercicio tienes que calcular el **n√∫mero total de sesiones por cada juego**, usando MapReduce.  \n",
    "Cada fila del dataset representa una sesi√≥n individual de un usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f146b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "import sys\n",
    "\n",
    "header_line = True\n",
    "\n",
    "data = sys.stdin\n",
    "\n",
    "for line in data:\n",
    "    if header_line:\n",
    "        header_line = False\n",
    "        continue\n",
    "    line = line.strip()\n",
    "    line = line.split(',')\n",
    "\n",
    "    game_name = line[1]\n",
    "    \n",
    "    print(f\"{game_name},{1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d344716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "\n",
    "import sys\n",
    "\n",
    "# variables para los valores de cada iteraci√≥n\n",
    "sessions_per_game = {}\n",
    "\n",
    "# entrada desde STDIN\n",
    "for line in sys.stdin:\n",
    "    # eliminamos espacios blancos al principio y final\n",
    "    line = line.strip()\n",
    "\n",
    "    game, count = line.split(\",\")\n",
    "    \n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    if game in sessions_per_game:\n",
    "\n",
    "        sessions_per_game[game] += 1\n",
    "\n",
    "    else:\n",
    "\n",
    "        sessions_per_game[game] = 1\n",
    "\n",
    "for game, times in sessions_per_game.items():\n",
    "    print(f\"{game}, {times}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fec551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIFA, 325276\n",
      "Minecraft, 81340\n",
      "Valorant, 162440\n",
      "Call of Duty, 40489\n",
      "Fortnite, 64699\n",
      "League of Legends, 113755\n",
      "Overwatch, 65229\n",
      "Rocket League, 73400\n",
      "Among Us, 40772\n",
      "Apex Legends, 32600\n"
     ]
    }
   ],
   "source": [
    "# Comando de ejecuci√≥n en Hadoop\n",
    "!cat $MATERIALES/game_sessions_1Mi.csv | python3 mapper.py | python3 reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92448bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Contenido de HDFS de salida del ejercicio 1:\n",
      "ls: `/user/shared/01/salida': No such file or directory\n",
      "cat: `/user/shared/01/salida/part-*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n de resultados en HDFS del ejercicio 1\n",
    "!echo 'üìÇ Contenido de HDFS de salida del ejercicio 1:'\n",
    "!hdfs dfs -ls $HDFS_OUT\n",
    "!hdfs dfs -cat $HDFS_OUT/part-* | sort -k2,2nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31853ed3",
   "metadata": {},
   "source": [
    "### Ejercicio 2 ‚Äì Duraci√≥n media por regi√≥n\n",
    "\n",
    "Debes calcular la **duraci√≥n media de las sesiones** para cada regi√≥n de Europa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304c349e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "\n",
    "import sys\n",
    "\n",
    "header_line = True\n",
    "\n",
    "data = sys.stdin\n",
    "\n",
    "for line in data:\n",
    "    if header_line:\n",
    "        header_line = False\n",
    "        continue\n",
    "    line = line.strip()\n",
    "    line = line.split(',')\n",
    "\n",
    "    game_name = line[1]\n",
    "    mins_played = line[4]\n",
    "    \n",
    "    print(f\"{game_name},{mins_played}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "116e362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "\n",
    "import sys\n",
    "\n",
    "# variables para los valores de cada iteraci√≥n\n",
    "sessions_per_game = {}\n",
    "\n",
    "# entrada desde STDIN\n",
    "for line in sys.stdin:\n",
    "    # eliminamos espacios blancos al principio y final\n",
    "    line = line.strip()\n",
    "\n",
    "    game, count = line.split(\",\")\n",
    "    \n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    if game in sessions_per_game:\n",
    "\n",
    "        sessions_per_game[game].append(count)\n",
    "\n",
    "    else:\n",
    "        sessions_per_game[game] = [count]\n",
    "\n",
    "for game, times in sessions_per_game.items():\n",
    "    total_mins = sum(times)\n",
    "    media_mins = total_mins / len(times)\n",
    "    print(f\"{game}, {media_mins}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15071170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197, 95.4245283018868\n",
      "694, 99.20992761116857\n",
      "299, 101.50324675324676\n",
      "52, 226.3980044345898\n",
      "71, 222.07841031149303\n",
      "765, 99.57049180327868\n",
      "671, 98.39957035445757\n",
      "136, 100.51859723698193\n",
      "150, 100.1659090909091\n",
      "808, 101.66203703703704\n"
     ]
    }
   ],
   "source": [
    "# Comando de ejecuci√≥n en Hadoop\n",
    "!cat $MATERIALES/game_sessions_1Mi.csv | python3 mapper.py | python3 reducer.py | tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3777812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Contenido de HDFS de salida del ejercicio 2:\n",
      "ls: `/user/shared/02/salida': No such file or directory\n",
      "cat: `/user/shared/02/salida/part-*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n de resultados en HDFS del ejercicio 2\n",
    "!echo 'üìÇ Contenido de HDFS de salida del ejercicio 2:'\n",
    "!hdfs dfs -ls $HDFS_OUT\n",
    "!hdfs dfs -cat $HDFS_OUT/part-* | sort -k2,2nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49585e5",
   "metadata": {},
   "source": [
    "### Ejercicio 3 ‚Äì Puntuaci√≥n media por jugador\n",
    "\n",
    "Determina la **puntuaci√≥n media de cada jugador (`user_id`)** a lo largo de sus partidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8186890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "\n",
    "import sys\n",
    "\n",
    "header_line = True\n",
    "\n",
    "data = sys.stdin\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    if header_line:\n",
    "        header_line = False\n",
    "        continue\n",
    "        \n",
    "    line = line.strip()\n",
    "    line = line.split(',')\n",
    "\n",
    "    user_id = line[0]\n",
    "    score = line[5]\n",
    "\n",
    "    print(f\"{user_id},{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea10eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "\n",
    "import sys\n",
    "\n",
    "# variables para los valores de cada iteraci√≥n\n",
    "user_avg_score = {}\n",
    "\n",
    "# entrada desde STDIN\n",
    "for line in sys.stdin:\n",
    "    # eliminamos espacios blancos al principio y final\n",
    "    line = line.strip()\n",
    "\n",
    "    user, count = line.split(\",\")\n",
    "    \n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    if user in user_avg_score:\n",
    "\n",
    "        user_avg_score[user].append(count)\n",
    "\n",
    "    else:\n",
    "        user_avg_score[user] = [count]\n",
    "\n",
    "for game, times in user_avg_score.items():\n",
    "    total_mins = sum(times)\n",
    "    media_mins = total_mins / len(times)\n",
    "    print(f\"{game}, {media_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e6690d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197, 95.4245283018868\n",
      "694, 99.20992761116857\n",
      "299, 101.50324675324676\n",
      "52, 226.3980044345898\n",
      "71, 222.07841031149303\n",
      "765, 99.57049180327868\n",
      "671, 98.39957035445757\n",
      "136, 100.51859723698193\n",
      "150, 100.1659090909091\n",
      "808, 101.66203703703704\n"
     ]
    }
   ],
   "source": [
    "# Comando de ejecuci√≥n en Hadoop\n",
    "!cat $MATERIALES/game_sessions_1Mi.csv | python3 mapper.py | python3 reducer.py | tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n de resultados en HDFS del ejercicio 3\n",
    "!echo 'üìÇ Contenido de HDFS de salida del ejercicio 3:'\n",
    "!hdfs dfs -ls $HDFS_OUT\n",
    "!hdfs dfs -cat $HDFS_OUT/part-* | sort -k2,2nr | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e820d8b",
   "metadata": {},
   "source": [
    "### Ejercicio 4 ‚Äì Top 5 jugadores con m√°s victorias\n",
    "\n",
    "Identifica los **5 jugadores con m√°s victorias** (`team_result='WIN'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ee0d654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "\n",
    "import sys\n",
    "\n",
    "header_line = True\n",
    "\n",
    "data = sys.stdin\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    if header_line:\n",
    "        header_line = False\n",
    "        continue\n",
    "\n",
    "    line = line.strip()\n",
    "    line = line.split(',')\n",
    "\n",
    "    user = line[0]\n",
    "    result = line[7]\n",
    "\n",
    "    print(f\"{user},{result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b95141d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "\n",
    "import sys\n",
    "\n",
    "top_scores = {}\n",
    "\n",
    "data = sys.stdin\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    line = line.strip()\n",
    "    user, result = line.split(',')\n",
    "\n",
    "    if user in top_scores:\n",
    "        top_scores[user] += 1\n",
    "\n",
    "    else:\n",
    "        top_scores[user] = 1\n",
    "\n",
    "sorted_top_scores = dict(sorted(top_scores.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "print(sorted_top_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9bdd147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': 12613, '9': 11645, '8': 10572, '7': 9427, '6': 8522}\n"
     ]
    }
   ],
   "source": [
    "# Comando de ejecuci√≥n en Hadoop\n",
    "!cat $MATERIALES/game_sessions_1Mi.csv | python3 mapper.py | python3 reducer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf46098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n de resultados en HDFS del ejercicio 4\n",
    "!echo 'üìÇ Contenido de HDFS de salida del ejercicio 4:'\n",
    "!hdfs dfs -ls $HDFS_OUT\n",
    "!hdfs dfs -cat $HDFS_OUT/part-* | sort -k2,2nr | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c4b9f",
   "metadata": {},
   "source": [
    "### Ejercicio 5 ‚Äì Distribuci√≥n por plataforma y resultado\n",
    "\n",
    "Calcula la **distribuci√≥n de partidas por plataforma y resultado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3043fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "\n",
    "import sys\n",
    "\n",
    "header_line = True\n",
    "\n",
    "data = sys.stdin\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    if header_line:\n",
    "        header_line = False\n",
    "        continue\n",
    "\n",
    "    line = line.strip()\n",
    "    line = line.split(',')\n",
    "\n",
    "    platform = line[3]\n",
    "    result = line[7]\n",
    "\n",
    "    print(f\"{platform},{result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df2e49cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "\n",
    "import sys\n",
    "\n",
    "def checkIfIsThere(dict, value):\n",
    "    if value in dict:\n",
    "        dict[value] += 1\n",
    "\n",
    "    else:\n",
    "        dict[value] = 1\n",
    "\n",
    "data = sys.stdin\n",
    "\n",
    "platforms_results = {}\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    line = line.strip()\n",
    "    platform, result = line.split(',')\n",
    "\n",
    "    if platform in platforms_results:\n",
    "        checkIfIsThere(platforms_results[platform], result)\n",
    "    else:\n",
    "        platforms_results[platform] = {}\n",
    "        checkIfIsThere(platforms_results[platform], result)\n",
    "\n",
    "print(platforms_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4f8b6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PC': {'LOSE': 180324, 'DRAW': 180003, 'WIN': 240195}, 'Console': {'WIN': 100087, 'DRAW': 74821, 'LOSE': 75269}, 'Mobile': {'LOSE': 44688, 'WIN': 59827, 'DRAW': 44786}}\n"
     ]
    }
   ],
   "source": [
    "# Comando de ejecuci√≥n en Hadoop\n",
    "!cat $MATERIALES/game_sessions_1Mi.csv | python3 mapper.py | python3 reducer.py | tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91578a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n de resultados en HDFS del ejercicio 5\n",
    "!echo 'üìÇ Contenido de HDFS de salida del ejercicio 5:'\n",
    "!hdfs dfs -ls $HDFS_OUT\n",
    "!hdfs dfs -cat $HDFS_OUT/part-* | sort -k2,2nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547aed4-c97f-41c2-84ed-3da929dd6d23",
   "metadata": {},
   "source": [
    "Una vez que hayas terminado todos los ejercicios, recuerda **guardar tu cuaderno de Jupyter** y descargarlo a tu ordenador.  \n",
    "Despu√©s, sube el archivo a la plataforma online para entregar tu trabajo.  \n",
    "**No olvides** incluir tu nombre y apellidos al pricipio de este documento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
